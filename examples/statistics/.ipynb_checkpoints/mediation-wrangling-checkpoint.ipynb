{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.mediation import Mediation\n",
    "from os.path import join\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jili_sidak_mc(data, alpha):\n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    mc_corrmat = data.corr()\n",
    "    mc_corrmat.fillna(0, inplace=True)\n",
    "    eigvals, eigvecs = np.linalg.eig(mc_corrmat)\n",
    "\n",
    "    M_eff = 0\n",
    "    for eigval in eigvals:\n",
    "        if abs(eigval) >= 0:\n",
    "            if abs(eigval) >= 1:\n",
    "                M_eff += 1\n",
    "            else:\n",
    "                M_eff += abs(eigval) - math.floor(abs(eigval))\n",
    "        else:\n",
    "            M_eff += 0\n",
    "    print('Number of effective comparisons: {0}'.format(M_eff))\n",
    "\n",
    "    #and now applying M_eff to the Sidak procedure\n",
    "    sidak_p = 1 - (1 - alpha)**(1/M_eff)\n",
    "    if sidak_p < 0.00001:\n",
    "        print('Critical value of {:.3f}'.format(alpha),'becomes {:2e} after corrections'.format(sidak_p))\n",
    "    else:\n",
    "        print('Critical value of {:.3f}'.format(alpha),'becomes {:.6f} after corrections'.format(sidak_p))\n",
    "    return sidak_p, M_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_corr(subjects, nodes, task, condition, session, atlas):\n",
    "    if len(nodes) > 1:\n",
    "        errors = pd.DataFrame(index=subjects, columns=nodes)\n",
    "        edges = pd.DataFrame(index=subjects)\n",
    "        for subject in subjects:\n",
    "            try:\n",
    "                if condition != None:\n",
    "                    corrmat = np.genfromtxt(join(sink_dir, \n",
    "                                                 'corrmats', \n",
    "                                                 '{0}-session-{1}_{2}-{3}_{4}-corrmat.csv'.format(subject, \n",
    "                                                                                                            session, \n",
    "                                                                                                            task, \n",
    "                                                                                                            condition, \n",
    "                                                                                                            atlas)),\n",
    "                                            delimiter=' ')\n",
    "                else:\n",
    "                    corrmat = np.genfromtxt(join(sink_dir, \n",
    "                                                 'corrmats', \n",
    "                                                 '{0}-session-{1}-{2}_network_corrmat_{3}.csv'.format(subject, \n",
    "                                                                                                            session, \n",
    "                                                                                                            task, \n",
    "                                                                                                            atlas)),\n",
    "                                            delimiter=',')\n",
    "                for pair in nodes:\n",
    "                    node1 = pair[0] - 1\n",
    "                    node2 = pair[1] - 1\n",
    "                    edges.at[subject,'{0}_{1}_{2}.{3}_edge'.format(task, mask, pair[0], pair[1])] = corrmat[node1][node2]\n",
    "                #post_retr_conn.at[subject] = np.ravel(corrmat, order='F')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        \n",
    "    else:\n",
    "        errors = pd.Series(index=subjects)\n",
    "        edges = pd.Series(index=subjects)\n",
    "        node1 = nodes[0] - 1\n",
    "        node2 = nodes[1] - 1\n",
    "        for subject in subjects:\n",
    "            try:\n",
    "                if condition != None:\n",
    "                    corrmat = np.genfromtxt(join(sink_dir, \n",
    "                                                 'corrmats', \n",
    "                                                 '{0}-session-{1}_{2}-{3}_{4}-corrmat.csv'.format(subject, \n",
    "                                                                                                            session, \n",
    "                                                                                                            task, \n",
    "                                                                                                            condition, \n",
    "                                                                                                            atlas)),\n",
    "                                            delimiter=' ')\n",
    "                else:\n",
    "                    corrmat = np.genfromtxt(join(sink_dir, \n",
    "                                                 'corrmats', \n",
    "                                                 '{0}-session-{1}-{2}_network_corrmat_{3}.csv'.format(subject, \n",
    "                                                                                                            session, \n",
    "                                                                                                            task, \n",
    "                                                                                                            atlas)),\n",
    "                                            delimiter=',')\n",
    "                edges[subject] = corrmat[node1][node2]\n",
    "                #post_retr_conn.at[subject] = np.ravel(corrmat, order='F')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "    return edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = [101, 102, 103, 104, 106, 107, 108, 110, 212, 213,\n",
    "            214, 215, 216, 217, 218, 219, 320, 321, 322, 323,\n",
    "            324, 325, 327, 328, 329, 330, 331, 332, 333, 334,\n",
    "            335, 336, 337, 338, 339, 340, 341, 342, 343, 344,\n",
    "            345, 346, 347, 348, 349, 350, 451, 452, 453, 455,\n",
    "            456, 457, 458, 459, 460, 462, 463, 464, 465, 467,\n",
    "            468, 469, 470, 502, 503, 571, 572, 573, 574, 575,\n",
    "            577, 578, 579, 580, 581, 582, 584, 585, 586, 587,\n",
    "            588, 589, 590, 591, 592, 593, 594, 595, 596, 597,\n",
    "            598, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
    "            613, 614, 615, 616, 617, 618, 619, 620, 621, 622,\n",
    "            623, 624, 625, 626, 627, 628, 629, 630, 631, 633,\n",
    "            634]\n",
    "#subjects = [101, 102, 103]\n",
    "\n",
    "sink_dir = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/data/output'\n",
    "data_dir = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/data'\n",
    "roi_dir = '/Users/kbottenh/Dropbox/Data/templates/shen2015/'\n",
    "fig_dir = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/figures/'\n",
    "\n",
    "shen = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/shen2015_2mm_268_parcellation.nii.gz'\n",
    "craddock = '/home/kbott006/physics-retrieval/craddock2012_tcorr05_2level_270_2mm.nii.gz'\n",
    "masks = ['shen2015', 'craddock2012']\n",
    "\n",
    "tasks = ['retr', 'fci']\n",
    "conditions = ['phys', 'ctrl']\n",
    "sessions = ['pre', 'post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraphs = glob(join(sink_dir, '*FSIQ*iq*sig_edges.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in all-data df\n",
    "\n",
    "big_df = pd.read_csv(join(data_dir, \n",
    "                          'rescored', \n",
    "                          'physics_learning-local_efficiency-BayesianImpute.csv'), \n",
    "                     index_col=0, header=0)\n",
    "drop = big_df.filter(regex=\".*lEff.*\").columns\n",
    "big_df.drop(drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.rename({'post phys retr fd': 'post_phys_retr_fd', \n",
    "               'post phys fci fd': 'post_phys_fci_fd',\n",
    "               'Strt.Level': 'Strt_Level'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "craddock2012-fci_phys-FSIQ2_iqXSexXClass-sig_edges\n",
      "Int64Index([199], dtype='int64')\n",
      "Int64Index([234], dtype='int64')\n",
      "Int64Index([18], dtype='int64')\n",
      "Int64Index([52], dtype='int64')\n",
      "craddock2012-fci_phys-FSIQ2_iqXSexXClass-sig_edges (18, 234)\n",
      "(18, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXSexXClass-sig_edges (52, 234)\n",
      "(52, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXSexXClass-sig_edges (199, 234)\n",
      "(199, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXSexXClass-sig_edges (234, 234)\n",
      "(234, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXClass-sig_edges\n",
      "Int64Index([234], dtype='int64')\n",
      "Int64Index([52], dtype='int64')\n",
      "craddock2012-fci_phys-FSIQ2_iqXClass-sig_edges (52, 234)\n",
      "(52, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXClass-sig_edges (234, 234)\n",
      "(234, 234)\n",
      "shen2015-fci_phys-FSIQ2_iqXSexXClass-sig_edges\n",
      "Int64Index([147], dtype='int64')\n",
      "Int64Index([36], dtype='int64')\n",
      "shen2015-fci_phys-FSIQ2_iqXSexXClass-sig_edges (36, 234)\n",
      "(36, 234)\n",
      "shen2015-fci_phys-FSIQ2_iqXSexXClass-sig_edges (147, 234)\n",
      "(147, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXSex-sig_edges\n",
      "Int64Index([199], dtype='int64')\n",
      "Int64Index([18], dtype='int64')\n",
      "craddock2012-fci_phys-FSIQ2_iqXSex-sig_edges (18, 234)\n",
      "(18, 234)\n",
      "craddock2012-fci_phys-FSIQ2_iqXSex-sig_edges (199, 234)\n",
      "(199, 234)\n",
      "Number of effective comparisons: 15.438137913511575\n",
      "Critical value of 0.050 becomes 0.003317 after corrections\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0033169918449631464, 15.438137913511575)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for subgraph in subgraphs:\n",
    "    regression = subgraph[63:-4]\n",
    "    print(regression)\n",
    "    keys = regression.split('-')\n",
    "    mask = keys[0]\n",
    "    condition = 'Physics'\n",
    "    task = keys[1].split('_')[0]\n",
    "    iq = keys[2].split('_')[0]\n",
    "    cov = keys[2].split('_')[1]\n",
    "\n",
    "    conns = pd.read_csv(subgraph, index_col=0, header=0)\n",
    "\n",
    "    conns.dropna(how='all', axis=0, inplace=True)\n",
    "    conns.dropna(how='all', axis=1, inplace=True)\n",
    "    conns.fillna(0, inplace=True)\n",
    "    \n",
    "    edges = []\n",
    "    for column in conns.columns:\n",
    "        ind = conns[conns[column] != 0].index\n",
    "        print(ind)\n",
    "        if len(ind) > 1:\n",
    "            for i in ind:\n",
    "                #print(column, i[0])\n",
    "                edges.append((int(column), i[0]))\n",
    "        else:\n",
    "            edges.append((int(column), i))\n",
    "\n",
    "    for edge in edges:\n",
    "        print(regression, edge)\n",
    "        print(edge)\n",
    "        #edges, error = grab_corr(big_df.index, edge, task, 'Physics', '1', mask)\n",
    "        #big_df = pd.concat([edges,big_df], axis=1)\n",
    "jili_sidak_mc(big_df.dropna(how='any'), 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'52'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv(join(sink_dir, 'mediation_edges.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shen2015\n",
      "craddock2012\n",
      "shen2015\n",
      "craddock2012\n"
     ]
    }
   ],
   "source": [
    "for task in tasks:\n",
    "    for mask in masks:\n",
    "        print(mask)\n",
    "        edge_df = pd.read_csv(join(sink_dir, '{0}-{1}_whole_brain-permuted_ols.csv'.format(task,mask)),\n",
    "                              index_col=[0,1,2], header=0)\n",
    "        edge_df.index.set_names(['wais', 'task', 'regressor'], inplace=True)\n",
    "        for i in edge_df.index:\n",
    "            edges = [pair for pair in edge_df.loc[i]['edges'].strip('[]').split('), (')]\n",
    "            tuples = []\n",
    "            if len(edges) > 1:\n",
    "                for edge in edges:\n",
    "                    edge_tup = (int(edge.strip('()').split(', ')[0]), int(edge.strip('()').split(', ')[1]))\n",
    "                    tuples.append(edge_tup)\n",
    "                np.savetxt(join(sink_dir, '{0}_{1}_{2}.tsv'.format(mask, task, i)), tuples, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '[(168'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9c4aa937a463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0miq_edge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'deltaPRI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fci'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edges'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miq_tup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miq_edge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miq_edge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'()'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_tup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '[(168'"
     ]
    }
   ],
   "source": [
    "iq_edge = edge_df.loc['deltaPRI', 'fci', 'iq']['edges']\n",
    "iq_tup = (int(iq_edge.strip('()').split(', ')[0]), int(iq_edge.strip('()').split(', ')[1]))\n",
    "tuples.append(edge_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.Series(index=edge_df.index)\n",
    "iq_edges = [pair for pair in edge_df.loc['deltaPRI', 'fci', 'iq']['edges'].strip('[]').split('), (')]\n",
    "iq_tuples = []\n",
    "if len(iq_edges) > 1:\n",
    "    for edge in iq_edges:\n",
    "        edge_tup = (int(edge.strip('()').split(', ')[0]), int(edge.strip('()').split(', ')[1]))\n",
    "        iq_tuples.append(edge_tup)\n",
    "iqs_edges = [pair for pair in edge_df.loc['deltaPRI', 'fci', 'iqXsex']['edges'].strip('[]').split('), (')]\n",
    "iqs_tuples = []\n",
    "if len(iqs_edges) > 1:\n",
    "    for edge in iqs_edges:\n",
    "        edge_tup = (int(edge.strip('()').split(', ')[0]), int(edge.strip('()').split(', ')[1]))\n",
    "        iqs_tuples.append(edge_tup)\n",
    "iqc_edges = [pair for pair in edge_df.loc['deltaPRI', 'fci', 'iqXclass']['edges'].strip('[]').split('), (')]\n",
    "iqc_tuples = []\n",
    "if len(iqc_edges) > 1:\n",
    "    for edge in iqc_edges:\n",
    "        edge_tup = (int(edge.strip('()').split(', ')[0]), int(edge.strip('()').split(', ')[1]))\n",
    "        iqc_tuples.append(edge_tup)\n",
    "iqsc_edges = [pair for pair in edge_df.loc['deltaPRI', 'fci', 'iqXsexXclass']['edges'].strip('[]').split('), (')]\n",
    "iqsc_tuples = []\n",
    "if len(iqsc_edges) > 1:\n",
    "    for edge in iqsc_edges:\n",
    "        edge_tup = (int(edge.strip('()').split(', ')[0]), int(edge.strip('()').split(', ')[1]))\n",
    "        iqsc_tuples.append(edge_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(iqs_tuples) & set(iqc_tuples) & set(iqsc_tuples) & set(iq_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join(sink_dir, 'mediation_edges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df.columns.str.endswith('.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df = pd.read_csv(join(sink_dir, 'mediation_edges.csv'), sep='\\t')\n",
    "for i in np.arange(0,5):\n",
    "    drops = renamed_df.columns.str.endswith('.{0}'.format(i))\n",
    "    renamed_df.drop(renamed_df.columns[drops], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df.to_csv(join(sink_dir, 'mediation_edges.csv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
