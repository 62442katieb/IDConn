{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T22:27:28.619955Z",
     "start_time": "2020-04-02T22:27:24.634240Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "import bct\n",
    "import json\n",
    "from os import makedirs\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from os.path import join, exists\n",
    "from nilearn.plotting import plot_glass_brain, plot_roi, find_parcellation_cut_coords\n",
    "#import bct\n",
    "import datetime\n",
    "from nilearn.mass_univariate import permuted_ols\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "sns.set_context('poster', font_scale=0.85)\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-31T16:59:06.811940Z",
     "start_time": "2020-03-31T16:59:06.793131Z"
    }
   },
   "outputs": [],
   "source": [
    "def jili_sidak_mc(data, alpha):\n",
    "    import math\n",
    "    import numpy as np\n",
    "\n",
    "    mc_corrmat = data.corr()\n",
    "    mc_corrmat.fillna(0, inplace=True)\n",
    "    eigvals, eigvecs = np.linalg.eig(mc_corrmat)\n",
    "\n",
    "    M_eff = 0\n",
    "    for eigval in eigvals:\n",
    "        if abs(eigval) >= 0:\n",
    "            if abs(eigval) >= 1:\n",
    "                M_eff += 1\n",
    "            else:\n",
    "                M_eff += abs(eigval) - math.floor(abs(eigval))\n",
    "        else:\n",
    "            M_eff += 0\n",
    "    print('Number of effective comparisons: {0}'.format(M_eff))\n",
    "\n",
    "    #and now applying M_eff to the Sidak procedure\n",
    "    sidak_p = 1 - (1 - alpha)**(1/M_eff)\n",
    "    if sidak_p < 0.00001:\n",
    "        print('Critical value of {:.3f}'.format(alpha),'becomes {:2e} after corrections'.format(sidak_p))\n",
    "    else:\n",
    "        print('Critical value of {:.3f}'.format(alpha),'becomes {:.6f} after corrections'.format(sidak_p))\n",
    "    return sidak_p, M_eff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sink_dir = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/data/output'\n",
    "fig_dir = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/figures/'\n",
    "data_dir = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/data'\n",
    "roi_dir = '/Users/kbottenh/Dropbox/Data/templates/shen2015/'\n",
    "\n",
    "\n",
    "shen = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/shen2015_2mm_268_parcellation.nii.gz'\n",
    "craddock = '/Users/kbottenh/Dropbox/Projects/physics-retrieval/craddock2012_tcorr05_2level_270_2mm.nii.gz'\n",
    "masks = ['shen2015', 'craddock2012']\n",
    "\n",
    "tasks = {'retr': [{'conditions': ['Physics', 'General']},\n",
    "                  {'runs': [0, 1]}],\n",
    "         'fci': [{'conditions': ['Physics', 'NonPhysics']},\n",
    "                 {'runs': [0, 1, 2]}]}\n",
    "\n",
    "tasks = ['fci', 'retr']\n",
    "sessions = [0, 1]\n",
    "sesh = ['pre', 'post']\n",
    "conditions = ['high-level', 'lower-level']\n",
    "iqs = ['VCI', 'WMI', 'PRI', 'PSI', 'FSIQ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling\n",
    "Nodal efficiency data needs to be scaled according to mean efficiency across empirically estimated null models. Imputation should happen, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Data wrangling\n",
    "# Nodal efficiency data is currently in an <i>incredbily</i> long, multi-indexed dataframe. \n",
    "# Here, we transform it into wide data (dataframe per condition per task per session) for ease of analysis later.\n",
    "null_df = pd.read_csv(join(sink_dir, 'local_efficiency', 'task_eff_dist.csv'), \n",
    "                      index_col=[0,1,2,3], header=0)\n",
    "\n",
    "big_df = pd.read_csv(join(data_dir, 'rescored', 'physics_learning-local_efficiency-BayesianImpute.csv'), \n",
    "                index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask in masks:\n",
    "    for session in sessions:\n",
    "        for task in tasks:\n",
    "            for condition in conditions:\n",
    "                if condition == 'high-level':\n",
    "                    cond = 'physics'\n",
    "                elif condition == 'lower-level':\n",
    "                    cond = 'control'\n",
    "                conns = big_df.filter(regex='(\\'*\\', {0}, \\'{1}\\', \\'{2}\\', \\'{3}\\')'.format(session, \n",
    "                                                                                             task, \n",
    "                                                                                             condition, \n",
    "                                                                                             mask)).columns\n",
    "                big_df[conns] = big_df[conns] = null_df.loc[sesh[session], \n",
    "                                                            task, \n",
    "                                                            cond, \n",
    "                                                            mask]['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iq in iqs:\n",
    "    big_df['delta{0}'.format(iq)] = big_df['{0}2'.format(iq)] - big_df['{0}1'.format(iq)]\n",
    "    big_df['delta{0}XSex'.format(iq)] = big_df['delta{0}'.format(iq)] * big_df['F']\n",
    "    big_df['{0}2XSex'.format(iq)] = big_df['{0}2'.format(iq)] * big_df['F']\n",
    "    big_df['delta{0}XClass'.format(iq)] = big_df['delta{0}'.format(iq)] * big_df['Mod']\n",
    "    big_df['{0}2XClass'.format(iq)] = big_df['{0}2'.format(iq)] * big_df['Mod']\n",
    "    big_df['SexXClass'] = big_df['F'] * big_df['Mod']\n",
    "    big_df['delta{0}XSexXClass'.format(iq)] = big_df['delta{0}'.format(iq)] * big_df['SexXClass']\n",
    "    big_df['{0}2XSexXClass'.format(iq)] = big_df['{0}2'.format(iq)] * big_df['SexXClass']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regress local efficiency on IQ and all the covariates\n",
    "- Permuted OLS tests each `target_var` independently, while regressing out `confounding_vars`, so to run a multiple regression, we test each variable of interest, separately, and put all other variables in the regression in with the confounds. This way, we can test interactions <i>with</i> main effects.\n",
    "- Maximum p-values are saved in `sig` dictionary and for each significant variable, the p- and t-values for each node are saved in `nodaleff_sig`.\n",
    "- For each regression, maximum <i>p</i>- and <i>t</i>-values are stored in `params`, along with nodes whose local efficiency is significantly related to each parameter, are stored <i> by variable</i>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-15315af63e56>, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-15315af63e56>\"\u001b[0;36m, line \u001b[0;32m30\u001b[0m\n\u001b[0;31m    nodaleff_sig['{0} {1} p'.format(var, key)] = p.T.reshape((,268))\u001b[0m\n\u001b[0m                                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "sig = pd.DataFrame(index=masks)\n",
    "for mask in masks:\n",
    "    effs = {'post phys fci': {'conns': big_df.filter(regex='(\\'*\\', 1, \\'fci\\', \\'high-level\\', \\'{0}\\')'.format(mask)).columns,\n",
    "                              'iqs': ['deltaPRI', 'deltaFSIQ', 'PRI2']},\n",
    "            'post phys retr': {'conns': big_df.filter(regex='(\\'*\\', 1, \\'retr\\', \\'high-level\\', \\'{0}\\')'.format(mask)).columns,\n",
    "                               'iqs': ['WMI2', 'VCI2', 'PSI2', 'FSIQ2', 'deltaPSI']}}\n",
    "    iqs = effs['post phys fci']['iqs'] + effs['post phys retr']['iqs']\n",
    "    variables = ['iq', 'iqXsex', 'iqXclass', 'iqXsexXclass', 'sexXclass', 'F', 'Mod', 'Age', 'StrtLvl', 'fd']\n",
    "    nodaleff_sig = pd.DataFrame(index=conns)\n",
    "    index = pd.MultiIndex.from_product([iqs, effs.keys(), variables])\n",
    "    params = pd.DataFrame(index=index, columns=['max nlog(p)', 'max t', 'nodes'])\n",
    "    for key in effs.keys():\n",
    "        print(key)\n",
    "        efficiencies = effs[key]['conns']\n",
    "        iqs = effs[key]['iqs']\n",
    "        \n",
    "        for iq in iqs:\n",
    "            print(iq)\n",
    "            variables = ['{0}'.format(iq), '{0}XSex'.format(iq), '{0}XClass'.format(iq), \n",
    "                         '{0}XSexXClass'.format(iq),\n",
    "                         'F', 'StrtLvl', 'SexXClass', 'Age', 'Mod', '{0} fd'.format(key)]\n",
    "            for var in variables:\n",
    "                covariates = list(set(variables) - set([var]))\n",
    "                p, t, _ = permuted_ols(big_df[var], \n",
    "                                       big_df[efficiencies], \n",
    "                                       big_df[covariates],\n",
    "                                       n_perm=10000)\n",
    "                print(key, var, 'max p-val:',  np.max(p[0]))\n",
    "                sig.at[mask, '{0}, {1}, {2}'.format(variables[0], key, var)] = np.max(p[0])\n",
    "                nodaleff_sig['{0} {1} p'.format(var, key)] = p.reshape((268,)).T\n",
    "                nodaleff_sig['{0} {1} t'.format(var, key)] = t.reshape((268,)).T\n",
    "                nodaleff_sig.to_csv(join(sink_dir, '{0}-{1}-{2}-{3}-nodal_efficiency-p+tvals.csv'.format(mask, key, iq, var)))\n",
    "                sig_nodes = nodaleff_sig[nodaleff_sig['{0} {1} p'.format(var, key)] >= 1].index\n",
    "                print('# significant nodes:', len(sig_nodes))\n",
    "                if key in var:\n",
    "                    params.loc[iq, key, 'fd']['max nlog(p)'] = np.max(p[0])\n",
    "                    params.loc[iq, key, 'fd']['max t'] = np.max(t[0])\n",
    "                    params.loc[iq, key, 'fd']['nodes'] = list(sig_nodes)\n",
    "                elif iq in var:\n",
    "                    if 'Sex' in var:\n",
    "                        if 'Class' in var:\n",
    "                            params.loc[iq, key, 'iqXsexXclass']['max nlog(p)'] = np.max(p[0])\n",
    "                            params.loc[iq, key, 'iqXsexXclass']['max t'] = np.max(t[0])\n",
    "                            params.loc[iq, key, 'iqXsexXclass']['nodes'] = list(sig_nodes)\n",
    "                        else:\n",
    "                            params.loc[iq, key, 'iqXsex']['max nlog(p)'] = np.max(p[0])\n",
    "                            params.loc[iq, key, 'iqXsex']['max t'] = np.max(t[0])\n",
    "                            params.loc[iq, key, 'iqXsex']['nodes'] = list(sig_nodes)\n",
    "                    if 'Class' in var:\n",
    "                        if not 'Sex' in var:\n",
    "                            params.loc[iq, key, 'iqXclass']['max nlog(p)'] = np.max(p[0])\n",
    "                            params.loc[iq, key, 'iqXclass']['max t'] = np.max(t[0])\n",
    "                            params.loc[iq, key, 'iqXclass']['nodes'] = list(sig_nodes)\n",
    "                    else:\n",
    "                        params.loc[iq, key, 'iq']['max nlog(p)'] = np.max(p[0])\n",
    "                        params.loc[iq, key, 'iq']['max t'] = np.max(t[0])\n",
    "                        params.loc[iq, key, 'iq']['nodes'] = list(sig_nodes)\n",
    "                elif var == 'SexXClass':\n",
    "                    params.loc[iq, key, 'sexXclass']['max nlog(p)'] = np.max(p[0])\n",
    "                    params.loc[iq, key, 'sexXclass']['max t'] = np.max(t[0])\n",
    "                    params.loc[iq, key, 'sexXclass']['nodes'] = list(sig_nodes)\n",
    "                else:\n",
    "                    params.loc[iq, key, var]['max nlog(p)'] = np.max(p[0])\n",
    "                    params.loc[iq, key, var]['max t'] = np.max(t[0])\n",
    "                    params.loc[iq, key, var]['nodes'] = list(sig_nodes)\n",
    "    params.to_csv(join(sink_dir, '{0}-params-permutedOLS-efficiency.csv'.format(mask)))\n",
    "sig.to_csv(join(sink_dir, 'max-nlogp-local_efficiency-permutedOLS.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 268)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in sig.columns:\n",
    "    if sig.at['shen2015', col] > 1.:\n",
    "        if sig.at['craddock2012', col] > 1.:\n",
    "            print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T00:07:28.075504Z",
     "start_time": "2020-04-01T00:07:27.703392Z"
    }
   },
   "outputs": [],
   "source": [
    "n_map = int(len(params[params['max nlog(p)'] > 1].index)) + 1\n",
    "interval = 1 / n_map\n",
    "husl_pal = sns.husl_palette(n_colors=n_map, h=interval)\n",
    "husl_cmap = LinearSegmentedColormap.from_list(husl_pal, husl_pal, N=n_map)\n",
    "sns.palplot(husl_pal)\n",
    "\n",
    "crayons_l = sns.crayon_palette(['Vivid Tangerine', 'Cornflower'])\n",
    "crayons_d = sns.crayon_palette(['Brick Red', 'Midnight Blue'])\n",
    "grays = sns.light_palette('#999999', n_colors=3, reverse=True)\n",
    "\n",
    "f_2 = sns.crayon_palette(['Red Orange', 'Vivid Tangerine'])\n",
    "m_2 = sns.crayon_palette(['Cornflower', 'Cerulean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-02T19:21:12.303416Z",
     "start_time": "2020-04-02T19:19:27.609827Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "empty_nii = nib.load(join(roi_dir, 'roi101.nii.gz'))\n",
    "empty_roi = empty_nii.get_fdata() * 0\n",
    "empty = nib.Nifti1Image(empty_roi, empty_nii.affine)\n",
    "g = plot_glass_brain(empty, colorbar=False, vmin=0.5, vmax=n_col)\n",
    "i = 0\n",
    "\n",
    "\n",
    "for var in params.index:\n",
    "    if params.loc[var]['max nlog(p)'] > 1:\n",
    "        i += 1\n",
    "        husl_pal = sns.husl_palette(h=interval * i, n_colors=n_map)\n",
    "        rois = None\n",
    "        print(i, var)\n",
    "        corr_nodes = []\n",
    "        #tvals = params.loc[i]['max t']\n",
    "        nodes = params.loc[var]['nodes']\n",
    "        corr_nodes.append(int(nodes[0].strip('lEff')))\n",
    "        roi_nifti = nib.load(join(roi_dir,'roi{0}.nii.gz'.format(int(nodes[0].strip('lEff')))))\n",
    "        roi = roi_nifti.get_fdata()\n",
    "        rois = (roi * i)\n",
    "        print(int(nodes[0].strip('lEff')), np.max(rois))\n",
    "        if len(nodes) > 1:\n",
    "            for node in nodes[1:]:\n",
    "                corr_nodes.append(int(node.strip('lEff')))\n",
    "                roi_nifti = nib.load(join(roi_dir,'roi{0}.nii.gz'.format(int(node.strip('lEff')))))\n",
    "                roi = roi_nifti.get_fdata()\n",
    "                rois += (roi * i)\n",
    "                print(int(node.strip('lEff')), np.max(rois))\n",
    "        else:\n",
    "            pass\n",
    "        np.savetxt(join(fig_dir, '{1}-{0}.txt'.format(i, var)), corr_nodes, delimiter=',')\n",
    "        rois_nifti = nib.Nifti1Image(rois, roi_nifti.affine)\n",
    "        rois_nifti.to_filename(join(data_dir, 'output/local_efficiency', '{0}_nodes.nii.gz'.format(var)))\n",
    "        h = plot_glass_brain(rois_nifti, cmap=LinearSegmentedColormap.from_list(husl_pal, husl_pal, N=3))\n",
    "        h.savefig(join(fig_dir, '{0}-{1}_ROIs.png'.format(i, var)), dpi=300)\n",
    "        \n",
    "        husl_pal = sns.husl_palette(n_colors=int(n_map), h=interval*i)\n",
    "        g.add_contours(rois_nifti, colors=husl_pal, filled=True, alpha=0.7)\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "g.savefig(join(fig_dir, 'LEffXIQ_ROIs.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-01T00:09:45.600766Z",
     "start_time": "2020-04-01T00:09:03.649859Z"
    }
   },
   "outputs": [],
   "source": [
    "n_col = int(len(nodaleff_sig.columns)/2) + 1\n",
    "husl_pal = sns.husl_palette(n_colors=int(n_col))\n",
    "husl_cmap = LinearSegmentedColormap.from_list(husl_pal, husl_pal, N=int(n_col))\n",
    "i = 0\n",
    "for var in params.index:\n",
    "    if params.loc[var]['max nlog(p)'] > 1:\n",
    "        iq = var[0]\n",
    "        task = var[1]\n",
    "        dat = effs[task]['conns']\n",
    "        husl_pal = sns.husl_palette(h=(interval*i), n_colors=int(n_col))\n",
    "\n",
    "        print(var, i)\n",
    "        all_data = pd.concat([big_df, dat[conns]], axis=1)\n",
    "        all_data.dropna(how='any', axis=0, inplace=True)\n",
    "        nodes = params.loc[var]['nodes']\n",
    "        print(nodes)\n",
    "        for node in nodes:\n",
    "            if var[-1] == 'iqXsex':\n",
    "                #print(iq, 'x Sex', node, nodaleff_sig.at[node,'{0}t'.format(var[:-1])])\n",
    "                h = sns.lmplot(iq, node, data=all_data, hue='F', palette=crayons_d)\n",
    "                h.savefig(join(fig_dir, '{0}-{1}-scatter.png'.format(i+1, var, node)), dpi=300)\n",
    "                plt.close()\n",
    "            elif var[-1] == 'iqXsexXclass':\n",
    "                #print(iq, 'x Sex x Class', node,  nodaleff_sig.at[node,'{0}t'.format(var[:-1])])\n",
    "                h = sns.lmplot(iq, node, data=all_data[all_data['F'] == 1], hue='Mod', palette=f_2)\n",
    "                h.savefig(join(fig_dir, '{0}-{1}-scatter-f.png'.format(i, var, node)), dpi=300)\n",
    "                h = sns.lmplot(iq, node, data=all_data[all_data['F'] == 0], hue='Mod', palette=m_2)\n",
    "                h.savefig(join(fig_dir, '{0}-{1}-scatter-m.png'.format(i+1, var, node)), dpi=300)\n",
    "                plt.close()\n",
    "            elif var[-1] == 'iqXclass':\n",
    "                #print(iq, 'x Class', node,  nodaleff_sig.at[node,'{0}t'.format(column[:-1])])\n",
    "                h = sns.lmplot(iq, node, data=all_data, hue='Mod', palette=grays)\n",
    "                h.savefig(join(fig_dir, '{0}-{1}-scatter.png'.format(i+1, var, node)), dpi=300)\n",
    "                plt.close()\n",
    "            elif var[-1] == 'sexXclass':\n",
    "                #print('Sex x Class', node,  nodaleff_sig.at[node,'{0}t'.format(column[:-1])])\n",
    "                h = sns.lmplot('F', node, data=all_data[all_data['F'] == 1], hue='Mod', palette=f_2)\n",
    "                h.savefig(join(fig_dir, '{0}-{1}-scatter-.png'.format(i+1, var, node)), dpi=300)\n",
    "                plt.close()\n",
    "            elif var[-1] == 'iq':\n",
    "                #print('no interxn', iq, node, nodaleff_sig.at[node,'{0}t'.format(column[:-1])])\n",
    "                fig,ax = plt.subplots()\n",
    "                sns.regplot(all_data[iq], all_data[node], color=husl_pal[0])\n",
    "                sns.despine()\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(join(fig_dir, '{0}-{1}-scatter.png'.format(i+1, var, node)), dpi=300)\n",
    "                plt.close()\n",
    "            elif var[-1] == 'fd':\n",
    "                pass\n",
    "            else:\n",
    "                fig,ax = plt.subplots()\n",
    "                sns.regplot(all_data[var[-1]], all_data[node], color=husl_pal[0])\n",
    "                sns.despine()\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(join(fig_dir, '{0}-{1}-scatter.png'.format(i+1, var, node)), dpi=300)\n",
    "                plt.close()\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
